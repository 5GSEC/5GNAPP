from http.server import BaseHTTPRequestHandler, HTTPServer
from flask import Flask # pip install flask
from flask import request, jsonify

import sdl_apis

# Gemini SDK
from google import genai
# OpenAI SDK
import openai

from flask import request
from flask_cors import CORS # pip install flask-cors
from flask import Response # NEW
import sqlite3
import json
import csv
import re
import os
import traceback # for debugging the agentic AI

app = Flask(__name__)
CORS(app) # for remote access


@app.route('/fetchServiceStatus', methods=['GET'])
def fetch_service_status():
    ''' Fetch the status of the SE-RAN services '''
    return sdl_apis.fetch_service_status_osc()


@app.route('/buildXapp', methods=['POST'])
def build_xapp():
    ''' Build xApp from the name specified in the request '''
    original_cwd = os.getcwd()
    logs = []  # We'll accumulate logs here

    data = request.get_json()
    if not data or 'xapp_name' not in data:
        return {"error": "xapp_name is required in the request body", "logs": logs}, 400

    xapp_name = data['xapp_name']
    return sdl_apis.build_xapp_osc(xapp_name)


@app.route('/deployXapp', methods=['POST'])
def deploy_xapp():
    ''' Deploy xApp from the name specified in the request '''
    data = request.get_json()
    if not data or 'xapp_name' not in data:
        return {
            "error": "xapp_name is required in the request body",
            "logs": logs
        }, 400

    xapp_name = data['xapp_name']
    return sdl_apis.deploy_xapp_osc(xapp_name)


@app.route('/unDeployXapp', methods=['POST'])
def unDeploy_xapp():
    ''' Undeploy xApp from the name specified in the request '''
    data = request.get_json()
    if not data or 'xapp_name' not in data:
        return {"error": "xapp_name is required in the request body"}, 400

    xapp_name = data['xapp_name']
    return sdl_apis.unDeploy_xapp_osc(xapp_name)

@app.route('/fetchSdlData', methods=['GET'])
def fetch_sdl_data():
    ''' Fetch network data from SDL '''
    return sdl_apis.fetch_sdl_data_osc()

@app.route('/fetchSdlEventData', methods=['GET'])
def fetch_sdl_event_data():
    ''' Fetch network event data generated by MobieXpert and MobiWatch from SDL '''
    return sdl_apis.fetch_sdl_event_data_osc()

FILE_PATH = os.path.join(
    os.getcwd(),                       # Get the current working directory
    "xApp", "MobieXpert", "src", "pbest", "expert", "rules.pbest" # Path to the rules file
)

# NEW: Define the route for fetching rules
@app.route("/api/mobieexpert/rules", methods=["GET"])
def get_rules():
    try:
        with open(FILE_PATH, "r", encoding="utf-8") as f:
            data = f.read()
        return Response(data, mimetype="text/plain")
    except FileNotFoundError:
        return {"error": f"{FILE_PATH} not found", "hint": "Have you built MobieXpert?"}, 404
    except Exception as e:
        return {"error": str(e)}, 500

#NEW: Define the route for updating rules
@app.route("/api/mobieexpert/rules", methods=["PUT"])
def put_rules():
    try:
        new_text = request.get_data(as_text=True)
        with open(FILE_PATH, "w", encoding="utf-8") as f:
            f.write(new_text)
        #return 204 for successful 
        return ("", 204)
    except Exception as e:
        return {"error": str(e)}, 500
    


#NEW: fake chat summary endpoint
@app.route('/chat/summary', methods=['GET'])
def get_chat_summary():
    """
    Fake chat summary endpoint.
    Returns a simple summary of base-station count and UE count.
    """
    # Static fake data
    summary = {
        "base_station_count": 5,
        "ue_count": 12
    }
    return summary, 200



# Global in-memory storage for LLM config
llm_config = {
    "api_key": None,
    "model": None
}

@app.route('/llm/config', methods=['GET', 'POST'])
def llm_config_route():
    if request.method == 'GET':
        return jsonify(llm_config), 200
    data = request.get_json() or {}
    llm_config['api_key'] = data.get('api_key')
    llm_config['model']   = data.get('model')
    return jsonify({"status": "ok"}), 200

@app.route('/llm/chat', methods=['POST'])
def llm_chat():
    """
    Receive user message and dispatch to the selected LLM.
    Supports Gemini via google-genai, and GPT via OpenAI.
    """
    body = request.get_json() or {}
    user_msg = body.get('message', '').strip()
    if not user_msg:
        return jsonify({"error": "No message provided"}), 400

    api_key = llm_config.get('api_key')
    model   = llm_config.get('model')
    if not api_key or not model:
        return jsonify({"error": "LLM config not set"}), 400

    # --- NEW: removing "models/"  ------------------------
    if model.startswith("models/"):
        model = model.split("/", 1)[1]          # -> "gemini-1.5-flash-latest"
    # --------------------------------------------------------

    try:
        # Gemini path
        if model.lower().startswith('gemini'):
            client = genai.Client(api_key=api_key)
            resp = client.models.generate_content(
                model=model,
                contents=user_msg
            )
            reply = resp.text

        # GPT path
        elif model.lower().startswith('gpt'):
            openai.api_key = api_key
            # Use chat completion for GPT-4
            chat_resp = openai.ChatCompletion.create(
                model=model,
                messages=[{"role":"user","content":user_msg}]
            )
            reply = chat_resp.choices[0].message.content.strip()

        else:
            return jsonify({"error": f"Unsupported model: {model}"}), 400

        return jsonify({"reply": reply}), 200

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/llm/models', methods=['GET'])
def llm_list_models():
    api_key = llm_config.get('api_key')
    if not api_key:
        return jsonify({"error": "LLM config not set"}), 400

    client = genai.Client(api_key=api_key)

    try:
        pager = client.models.list()               # returns a pager object
        model_list = [m.name for m in pager]      
        return jsonify({"models": model_list}), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500



if __name__ == "__main__":
    # run()
    app.run(host="0.0.0.0", port=8080, debug = True)
